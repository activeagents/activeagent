# This file is used to configure the Active Agent Generation Providers for different environments.
# Each provider can have its own settings, such as API keys and model configurations.
# Make sure to set the API keys in your Rails credentials for each generation provider before using them
# in your agent's `generate_with` config.

# region config_anchors
# region anthropic_anchor
anthropic: &anthropic
  service: "Anthropic"
  access_token: <%= Rails.application.credentials.dig(:anthropic, :access_token) %>
# endregion anthropic_anchor
# region openai_anchor
openai: &openai
  service: "OpenAI"
  access_token: <%= Rails.application.credentials.dig(:openai, :access_token) %>
# endregion openai_anchor
# region open_router_anchor
open_router: &open_router
  service: "OpenRouter"
  access_token: <%= Rails.application.credentials.dig(:open_router, :access_token) || Rails.application.credentials.dig(:open_router, :api_key) %>
# endregion open_router_anchor
# region ollama_anchor
ollama: &ollama
  service: "Ollama"
  access_token: ""
  host: "http://localhost:11434"
  model: "gemma3:latest"
  temperature: 0.7
# endregion ollama_anchor
# region onnx_runtime_anchor
onnx_runtime: &onnx_runtime
  service: "OnnxRuntime"
  model_type: "generation"
  model: "Xenova/gpt2"
  task: "text-generation"
  max_tokens: 50
  temperature: 0.7
# endregion onnx_runtime_anchor
# region onnx_embedding_anchor
onnx_embedding: &onnx_embedding
  service: "OnnxRuntime"
  model_type: "embedding"
  model: "Xenova/all-MiniLM-L6-v2"
  use_informers: true
# endregion onnx_embedding_anchor
# region transformers_anchor
transformers: &transformers
  service: "Transformers"
  model_type: "generation"
  model: "gpt2"
  task: "text-generation"
  max_tokens: 50
  temperature: 0.7
  do_sample: true
# endregion transformers_anchor
# region transformers_embedding_anchor
transformers_embedding: &transformers_embedding
  service: "Transformers"
  model_type: "embedding"
  model: "bert-base-uncased"
  task: "feature-extraction"
# endregion transformers_embedding_anchor
# region transformers_sentiment_anchor
transformers_sentiment: &transformers_sentiment
  service: "Transformers"
  model_type: "sentiment"
  model: "distilbert-base-uncased-finetuned-sst-2-english"
# endregion transformers_sentiment_anchor
# region ruby_llm_anchor
ruby_llm: &ruby_llm
  service: "RubyLLM"
  openai_api_key: <%= Rails.application.credentials.dig(:openai, :access_token) %>
  anthropic_api_key: <%= Rails.application.credentials.dig(:anthropic, :access_token) %>
  default_provider: "openai"
  model: "gpt-4o-mini"
  temperature: 0.7
  enable_image_generation: false
# endregion ruby_llm_anchor
# endregion config_anchors

# region config_development
development:
  # region openai_dev_config
  openai:
    <<: *openai
    model: "gpt-4o-mini"
    temperature: 0.7
  # endregion openai_dev_config
  # region open_router_dev_config
  open_router:
    <<: *open_router
    model: "qwen/qwen3-30b-a3b:free"
    temperature: 0.7
  # endregion open_router_dev_config
  # region ollama_dev_config
  ollama:
    <<: *ollama
  # endregion ollama_dev_config
  # region anthropic_dev_config
  anthropic:
    <<: *anthropic
  # endregion anthropic_dev_config
  # region ruby_llm_dev_config
  ruby_llm:
    <<: *ruby_llm
  # endregion ruby_llm_dev_config
# endregion config_development

# region config_test
test:
  openai:
    <<: *openai
    model: "gpt-4o-mini"
    temperature: 0.7
  open_router:
    <<: *open_router
    model: "qwen/qwen3-30b-a3b:free"
    temperature: 0.7
  ollama:
    <<: *ollama
  anthropic:
    <<: *anthropic
  ruby_llm:
    <<: *ruby_llm
# endregion config_test

---
http_interactions:
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4o-mini","messages":[{"role":"user","content":"Navigate
        to: https://www.example.com\n\nCapture the page content for structured data
        extraction:\n\n1. Navigate to the URL\n2. Wait for the page to fully load\n3.
        Use browser_snapshot to capture the accessibility tree\n4. Extract all text
        content\n5. Identify all interactive elements (links, buttons, forms)\n6.
        Note the page structure and hierarchy\n\nReturn a comprehensive description
        of the page content that can be used for structured data extraction.\nInclude:\n-
        Page title\n- All headings and their hierarchy\n- Main content areas\n- All
        links with their text and destinations\n- Form fields if present\n- Any data
        tables or lists\n- Important metadata\n\nUse Playwright MCP tools to gather
        this information systematically.\n"}],"temperature":0.7}'
    headers:
      Content-Type:
      - application/json
      Authorization:
      - Bearer <OPENAI_ACCESS_TOKEN>
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - "*/*"
      User-Agent:
      - Ruby
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sat, 13 Sep 2025 23:17:34 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Access-Control-Expose-Headers:
      - X-Request-ID
      Openai-Organization:
      - user-lwlf4w2yvortlzept3wqx7li
      Openai-Processing-Ms:
      - '8000'
      Openai-Project:
      - proj_KAJGwI6N1x3lWSKGr0zi2zcu
      Openai-Version:
      - '2020-10-01'
      X-Envoy-Upstream-Service-Time:
      - '8103'
      X-Ratelimit-Limit-Requests:
      - '10000'
      X-Ratelimit-Limit-Tokens:
      - '200000'
      X-Ratelimit-Remaining-Requests:
      - '9998'
      X-Ratelimit-Remaining-Tokens:
      - '199820'
      X-Ratelimit-Reset-Requests:
      - 10.083s
      X-Ratelimit-Reset-Tokens:
      - 54ms
      X-Request-Id:
      - req_0f29cd9af1124ce89fb85d3e694a20e9
      X-Openai-Proxy-Wasm:
      - v0.1
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - __cf_bm=iKXG700AEqs2b7AKeDHbjdMUVGhnmNTsZApitu8YgdA-1757805454-1.0.1.1-oUkJ5K8KglAZl4W0G5PqI39dc00CukOekPsov6OFmZPBJy6EDEprq3kGQ8vhgRBsSJARymum5YiPglH1NOdatyRenoU.YSnTeDu1H.bOKZk;
        path=/; expires=Sat, 13-Sep-25 23:47:34 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=TYiKRyGg4xSjn_s4k2Q5rvSm8sNEHF1Fw5VOcRuIRmU-1757805454529-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - 97eb5ba7add6cfdd-SJC
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "id": "chatcmpl-CFTmgzrhXnhMhmTWi1KLcCPQmgKj2",
          "object": "chat.completion",
          "created": 1757805446,
          "model": "gpt-4o-mini-2024-07-18",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "I'm unable to directly navigate to URLs or interact with web pages in real-time, including capturing page content or using browser automation tools like Playwright. However, I can guide you through the process of how you can do this yourself.\n\nHere's a step-by-step outline on how to use Playwright to extract structured data from a webpage:\n\n### Step 1: Set Up Playwright\n\n1. **Install Playwright**: If you haven't already, you can install Playwright using npm:\n   ```bash\n   npm install playwright\n   ```\n\n### Step 2: Create a Script\n\n2. **Create a new JavaScript file** (e.g., `extractData.js`) and include the following code structure:\n\n```javascript\nconst { chromium } = require('playwright');\n\n(async () => {\n    // Step 3: Launch the browser and navigate to the URL\n    const browser = await chromium.launch();\n    const page = await browser.newPage();\n    await page.goto('https://www.example.com');\n\n    // Step 4: Wait for the page to fully load\n    await page.waitForLoadState('load');\n\n    // Step 5: Capture the accessibility tree\n    const accessibilityTree = await page.accessibility.snapshot();\n\n    // Step 6: Extract all text content\n    const textContent = await page.evaluate(() => document.body.innerText);\n\n    // Step 7: Identify interactive elements\n    const interactiveElements = await page.$$eval('a, button, input, select, textarea', elements => {\n        return elements.map(el => ({\n            text: el.innerText,\n            tag: el.tagName,\n            href: el.tagName === 'A' ? el.href : null,\n            type: el.type || null,\n        }));\n    });\n\n    // Step 8: Note the page structure and hierarchy\n    const headings = await page.$$eval('h1, h2, h3, h4, h5, h6', headings => {\n        return headings.map(h => ({\n            text: h.innerText,\n            level: h.tagName,\n        }));\n    });\n\n    // Step 9: Form fields if present\n    const formFields = await page.$$eval('input, select, textarea', fields => {\n        return fields.map(field => ({\n            name: field.name,\n            type: field.type,\n            placeholder: field.placeholder,\n        }));\n    });\n\n    // Step 10: Data tables or lists\n    const lists = await page.$$eval('ul, ol', lists => {\n        return lists.map(list => ({\n            items: Array.from(list.children).map(item => item.innerText),\n        }));\n    });\n\n    // Step 11: Important metadata\n    const metadata = await page.evaluate(() => {\n        const metaTags = Array.from(document.getElementsByTagName('meta'));\n        return metaTags.map(tag => ({\n            name: tag.getAttribute('name'),\n            content: tag.getAttribute('content'),\n        }));\n    });\n\n    // Output gathered data\n    console.log({\n        textContent,\n        accessibilityTree,\n        interactiveElements,\n        headings,\n        formFields,\n        lists,\n        metadata,\n    });\n\n    // Close the browser\n    await browser.close();\n})();\n```\n\n### Step 3: Run the Script\n\n3. **Run your script** from the terminal:\n   ```bash\n   node extractData.js\n   ```\n\n### Expected Output\n\nThe script will output a JavaScript object containing:\n\n- **textContent**: All the text on the page.\n- **accessibilityTree**: The accessibility information for the page.\n- **interactiveElements**: An array of interactive elements with their text and destinations.\n- **headings**: An array of headings with their hierarchy.\n- **formFields**: An array of form field details.\n- **lists**: Any lists found on the page.\n- **metadata**: Important metadata elements.\n\n### Summary\n\nYou can modify the selectors and extraction logic based on the specific needs of the webpage you are working with. This script gives you a comprehensive overview of the page's content, which is suitable for structured data extraction.",
                "refusal": null,
                "annotations": []
              },
              "logprobs": null,
              "finish_reason": "stop"
            }
          ],
          "usage": {
            "prompt_tokens": 154,
            "completion_tokens": 838,
            "total_tokens": 992,
            "prompt_tokens_details": {
              "cached_tokens": 0,
              "audio_tokens": 0
            },
            "completion_tokens_details": {
              "reasoning_tokens": 0,
              "audio_tokens": 0,
              "accepted_prediction_tokens": 0,
              "rejected_prediction_tokens": 0
            }
          },
          "service_tier": "default",
          "system_fingerprint": "fp_51db84afab"
        }
  recorded_at: Sat, 13 Sep 2025 23:17:34 GMT
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4o-mini","messages":[{"role":"system","content":"You
        are a data extraction specialist that transforms unstructured content into
        structured JSON data.\n\nYour role is to:\n1. Analyze the provided content
        carefully\n2. Extract relevant information according to the schema\n3. Return
        well-structured JSON that matches the schema exactly\n4. Handle missing data
        gracefully with null or empty values\n5. Ensure all required fields are populated\n\nGuidelines:\n-
        Be precise and accurate in your extraction\n- Don''t invent data that isn''t
        present\n- Use reasonable defaults only when explicitly allowed by the schema\n-
        Maintain consistency in data formatting\n- Follow the schema''s type requirements
        strictly"},{"role":"user","content":"Extract structured data from the following
        content:\n\n---\nI''m unable to directly navigate to URLs or interact with
        web pages in real-time, including capturing page content or using browser
        automation tools like Playwright. However, I can guide you through the process
        of how you can do this yourself.\n\nHere''s a step-by-step outline on how
        to use Playwright to extract structured data from a webpage:\n\n### Step 1:
        Set Up Playwright\n\n1. **Install Playwright**: If you haven''t already, you
        can install Playwright using npm:\n   ```bash\n   npm install playwright\n   ```\n\n###
        Step 2: Create a Script\n\n2. **Create a new JavaScript file** (e.g., `extractData.js`)
        and include the following code structure:\n\n```javascript\nconst { chromium
        } = require(''playwright'');\n\n(async () =\u003e {\n    // Step 3: Launch
        the browser and navigate to the URL\n    const browser = await chromium.launch();\n    const
        page = await browser.newPage();\n    await page.goto(''https://www.example.com'');\n\n    //
        Step 4: Wait for the page to fully load\n    await page.waitForLoadState(''load'');\n\n    //
        Step 5: Capture the accessibility tree\n    const accessibilityTree = await
        page.accessibility.snapshot();\n\n    // Step 6: Extract all text content\n    const
        textContent = await page.evaluate(() =\u003e document.body.innerText);\n\n    //
        Step 7: Identify interactive elements\n    const interactiveElements = await
        page.$$eval(''a, button, input, select, textarea'', elements =\u003e {\n        return
        elements.map(el =\u003e ({\n            text: el.innerText,\n            tag:
        el.tagName,\n            href: el.tagName === ''A'' ? el.href : null,\n            type:
        el.type || null,\n        }));\n    });\n\n    // Step 8: Note the page structure
        and hierarchy\n    const headings = await page.$$eval(''h1, h2, h3, h4, h5,
        h6'', headings =\u003e {\n        return headings.map(h =\u003e ({\n            text:
        h.innerText,\n            level: h.tagName,\n        }));\n    });\n\n    //
        Step 9: Form fields if present\n    const formFields = await page.$$eval(''input,
        select, textarea'', fields =\u003e {\n        return fields.map(field =\u003e
        ({\n            name: field.name,\n            type: field.type,\n            placeholder:
        field.placeholder,\n        }));\n    });\n\n    // Step 10: Data tables or
        lists\n    const lists = await page.$$eval(''ul, ol'', lists =\u003e {\n        return
        lists.map(list =\u003e ({\n            items: Array.from(list.children).map(item
        =\u003e item.innerText),\n        }));\n    });\n\n    // Step 11: Important
        metadata\n    const metadata = await page.evaluate(() =\u003e {\n        const
        metaTags = Array.from(document.getElementsByTagName(''meta''));\n        return
        metaTags.map(tag =\u003e ({\n            name: tag.getAttribute(''name''),\n            content:
        tag.getAttribute(''content''),\n        }));\n    });\n\n    // Output gathered
        data\n    console.log({\n        textContent,\n        accessibilityTree,\n        interactiveElements,\n        headings,\n        formFields,\n        lists,\n        metadata,\n    });\n\n    //
        Close the browser\n    await browser.close();\n})();\n```\n\n### Step 3: Run
        the Script\n\n3. **Run your script** from the terminal:\n   ```bash\n   node
        extractData.js\n   ```\n\n### Expected Output\n\nThe script will output a
        JavaScript object containing:\n\n- **textContent**: All the text on the page.\n-
        **accessibilityTree**: The accessibility information for the page.\n- **interactiveElements**:
        An array of interactive elements with their text and destinations.\n- **headings**:
        An array of headings with their hierarchy.\n- **formFields**: An array of
        form field details.\n- **lists**: Any lists found on the page.\n- **metadata**:
        Important metadata elements.\n\n### Summary\n\nYou can modify the selectors
        and extraction logic based on the specific needs of the webpage you are working
        with. This script gives you a comprehensive overview of the page''s content,
        which is suitable for structured data extraction.\n---\n\n\nReturn the data
        in JSON format that strictly conforms to the provided schema.\nOnly include
        data that is actually present in the content.\nFor required fields that are
        missing, use appropriate null or empty values.\n"}],"temperature":0.7,"response_format":{"type":"json_schema","json_schema":{"name":"webpage_info","strict":true,"schema":{"type":"object","properties":{"title":{"type":"string"},"main_heading":{"type":"string"},"links_count":{"type":"integer"},"has_forms":{"type":"boolean"},"main_content_summary":{"type":"string"}},"required":["title","main_heading","links_count","has_forms","main_content_summary"],"additionalProperties":false}}}}'
    headers:
      Content-Type:
      - application/json
      Authorization:
      - Bearer <OPENAI_ACCESS_TOKEN>
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - "*/*"
      User-Agent:
      - Ruby
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sat, 13 Sep 2025 23:17:38 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Access-Control-Expose-Headers:
      - X-Request-ID
      Openai-Organization:
      - user-lwlf4w2yvortlzept3wqx7li
      Openai-Processing-Ms:
      - '1716'
      Openai-Project:
      - proj_KAJGwI6N1x3lWSKGr0zi2zcu
      Openai-Version:
      - '2020-10-01'
      X-Envoy-Upstream-Service-Time:
      - '2912'
      X-Ratelimit-Limit-Requests:
      - '10000'
      X-Ratelimit-Limit-Tokens:
      - '200000'
      X-Ratelimit-Remaining-Requests:
      - '9997'
      X-Ratelimit-Remaining-Tokens:
      - '198826'
      X-Ratelimit-Reset-Requests:
      - 17.343s
      X-Ratelimit-Reset-Tokens:
      - 352ms
      X-Request-Id:
      - req_412cac7f629e44f4b0dbd6c0ff9aec4e
      X-Openai-Proxy-Wasm:
      - v0.1
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - __cf_bm=OPMVEUYCviLP_ffGCX_FqxTXa.rz1fZ8Mu1bSkv7b0k-1757805458-1.0.1.1-_w169oUhsRK8X8J4qzgX4_126DEJTwNl2SXbhpJeFIp.qo4P9_cK2sM4eEDA9PYOmIYWRdRJNqAdeZUcQfMZfhSKZ4OIdIC_lJJHUY.aRqc;
        path=/; expires=Sat, 13-Sep-25 23:47:38 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=w_kzJxivGW2qGnr1xCPwRzQlevY_CtGIs99gLf3vfp0-1757805458169-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - 97eb5bdd2e78cf6d-SJC
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "id": "chatcmpl-CFTmqannnmK8xDAXmy8tOiTeIeLuP",
          "object": "chat.completion",
          "created": 1757805456,
          "model": "gpt-4o-mini-2024-07-18",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "{\"title\":\"\" ,\"main_heading\":\"\" ,\"links_count\":0 ,\"has_forms\":false ,\"main_content_summary\":\"This content provides a step-by-step guide on how to use Playwright for extracting structured data from a webpage, including setting up Playwright, creating a script, and running it to gather various types of data such as text content, accessibility trees, interactive elements, headings, form fields, lists, and metadata.\"}",
                "refusal": null,
                "annotations": []
              },
              "logprobs": null,
              "finish_reason": "stop"
            }
          ],
          "usage": {
            "prompt_tokens": 1080,
            "completion_tokens": 87,
            "total_tokens": 1167,
            "prompt_tokens_details": {
              "cached_tokens": 0,
              "audio_tokens": 0
            },
            "completion_tokens_details": {
              "reasoning_tokens": 0,
              "audio_tokens": 0,
              "accepted_prediction_tokens": 0,
              "rejected_prediction_tokens": 0
            }
          },
          "service_tier": "default",
          "system_fingerprint": "fp_560af6e559"
        }
  recorded_at: Sat, 13 Sep 2025 23:17:38 GMT
recorded_with: VCR 6.3.1
